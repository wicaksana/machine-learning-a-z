border = 0)
h <- hist(fertility,
prob = TRUE,
ylim = c(0, 0.04),
xlim = c(30, 100),
breaks = 11,
col = "#E5E5E5",
border = 0)
curve(dnorm((x,
mean = mean(fertility),
sd = sd(fertility)),
col = "red",
lwd = 3,
add = TRUE)
rm(list = ls())
# LOAD DATASET
require("datasets")
?swiss
swiss
str(swiss)
data(swiss)
fertility <- swiss$Fertility
# PLOTS
# Plot 1: Histogram
h <- hist(fertility,
prob = TRUE,  # Flipside of "freq = FALSE"
ylim = c(0, 0.04),
xlim = c(30, 100),
breaks = 11,
col = "#E5E5E5",
border = 0,
main = "Fertility for 47 French-Speaking\nSwiss Provinces, c. 1888")
# Plot 2: Normal curve (if prob = TRUE)
curve(dnorm(x, mean = mean(fertility), sd = sd(fertility)),
col = "red",
lwd = 3,
add = TRUE)
lines(density(fertility), col = "blue")
lines(density(fertility, adjust = 3), col = "darkgreen")
rug(fertility, col = "red")
install.packages("ggplot2")
install.packages("tm", dependencies=TRUE)
install.packages("arm")
install.packages("reshape")
install.packages("glmnet")
install.packages("igraph")
install.packages("reshape")
install.packages("XML")
install.packages("igraph")
install.packages("RJSONIO")
install.packages("lme4")
install.packages("RCurl")
install.packages("lubridate")
install.packages("RColorBrewer")
source('~/data_science/R/first.R')
require("ggplot2")
require("datasets")
rm(list = ls())
iris
str(iris)
data("iris")
petal.length <- iris$Petal.Length
h <- hist(petal.length,
probability = TRUE)
border = 0)
h <- hist(petal.length,
probability = TRUE,
breaks = 11,
col = "#E5E5E5",
border = 0)
lines(density(petal.length), col("blue"))
lines(density(petal.length), col = "blue")
lines(density(petal.length, adjust = 3), col = "darkgreen")
rug(petal.length, col = "red")
h <- hist(petal.length,
probability = TRUE,
breaks = 11,
col = "#E5E5E5",
border = 0,
main = "Petal Length")
# kernel density
lines(density(petal.length), col = "blue")
lines(density(petal.length, adjust = 3), col = "darkgreen")
# rug
rug(petal.length, col = "red")
rug(petal.length, col = "darkgray")
h <- hist(petal.length,
probability = TRUE,  # to superimpose with KDL
breaks = 12,
col = "#E5E5E5",
border = 0,
main = "Petal Length")
# kernel density
lines(density(petal.length), col = "blue")
# rug
rug(petal.length, col = "darkgray")
groups <- c(rep("blue", 3990),
rep("red", 4140),
rep("orange", 1890),
rep("green", 3770),
rep("purple", 855))
rm(list = ls())
groups <- c(rep("blue", 3990),
rep("red", 4140),
rep("orange", 1890),
rep("green", 3770),
rep("purple", 855))
groups.t1 <- table(groups)
groups.t1
gorups.t2 <- sort(groups.t1, decreasing = TRUE)
groups.t2 <- sort(groups.t1, decreasing = TRUE)
groups.t2
prop.table(groups.t2)
round(prop.table(groups.t2), 2)
round(prop.table(groups.t2), 2) * 100
rm(list = ls())
groups <- c(rep("blue", 3990),
rep("red", 4140),
rep("orange", 1890),
rep("green", 3770),
rep("purple", 855))
groups
groups.t1 <- table(groups)
groups.t1
groups.t2 <- sort(groups.t1, decreasing = TRUE)
groups.t2
prop.table(groups.t2)
round(prop.table(groups.t2), 2) * 100
rm(list = ls())
require("datasets")
cars
str(cars)
summary(cars$speed)
summary(cars)
fivenum(cars$speed)
boxplot.stats(cars$speed)
boxplot.stats(cars$speed)
boxplot(cars$speed)
rm(list = ls())
prop.test(98, 162)
prop.test(98, 162, alt = "greater", conf.level = .90)
rm(list = ls())
quakes[1:5,]
mag <- quakes$mag
mag[1:5]
t.test(mag)
t.test(mag, alternative = "greater", mu = 4)
rm(list = ls())
?HairEyeColor
str(HairEyeColor)
HairEyeColor
margin.table(HairEyeColor, 2)
eyes <- margin.table(HairEyeColor, 2)
eyes
round(prop.table(eyes), 2)
chi1 <- chisq.test(eyes)
chi1
chi2 <- chisq.test(eyes, p = c(.41, .32, .15, .12))
chi2
rm(list = ls())
?state.area
area <- state.area
area
hist(area)
boxplot(area)
boxplot.stats(area)
summary(area)
mean(area)
median(area)
mean(area, trim = .05) # 5% from each end (10% total)
mean(area, trim = .1)
sd(area) # not robust
mad(area) # median absolute deviation
IQR(area) # interquartile range
fivenum(area)
rm(list = ls())
require("dataset")
require("datasets")
str(mtcars)
mpg <- mtcars$mpg
hp <- mtcars$hp
qsec <- mtcars$qsec
mean(mpg)
hist(mpg)
hist(mpg)
hist(hp)
hist(qsec)
hist(mpg)
hist(hp)
hist(qsec)
mean(hp)
mean(qsec)
sd(mpg)
sd(hp)
mean(hp)
sd(qsec)
OS <- read.csv("OS")
OS <- read.csv("data_science/R/OS.csv")
OS
View(OS)
OS.hi <- subset(OS, Proportion > 0.1)
OS.hi
require("datasets")
data(rivers)
hist(rivers)
hist(rivers)
boxplot(rivers, horizontal = TRUE)
boxplot.stats(rivers)
rivers.low <- rivers[rivers < 1210]
boxplot(rivers.low, horizontal = TRUE)
boxplot.stats(rivers.low)
rm(list = ls())
install.packages("psych")
INFINITY = 10000
x <- seq(120, 240, length = INFINITY)
plot(x,
y,
type = 'l',
xlab = 'x',
ylab = 'density')
y <- dnorm(x, 180, 10)
plot(x,
y,
type = 'l',
xlab = 'x',
ylab = 'density')
?seq
?dnorm
abline(v = 180,
lwd = 2,
col = 'blue')
set.seed(79)
population <- rnorm(N, 180, 10)
abline(v = mean(population),
lwd = 4,
col = 'red',
lty = 2)
population <- rnorm(N, 180, 10)
abline(v = mean(population),
lwd = 4,
col = 'red',
lty = 2)
population <- rnorm(N, 180, 10)
INFINITY = 10000
population <- rnorm(N, 180, 10)
N = 501  # population
population <- rnorm(N, 180, 10)
abline(v = mean(population),
lwd = 4,
col = 'red',
lty = 2)
n = 30
x <-sample(population, n)
abline(v = mean(X),
lty = 3)
?rnorm
rnorm(15)
rnorm(15) * 100
weight  <- c(1,2,3,5,10,12)
weight
mean(weight)
height  <- c(1.75, 1.8, 1.6, 1.9, 1.74, 1.91)
bmi  <- weight / height^2
bmi
sum(weight)
sum(weight) / length(weight)
xbar  <- sum(weight) / length(weight)
weight - xbar
(weight - xbar)^2
sd(weight)
rm(list = ls())
weight <- c(60, 72, 57, 90, 95, 72)
height <- c(1.75, 1.80, 1.65, 1.90, 1.74, 1.91)
bmi <- weight/height^2
bmi
t.test(bmi,)
t.test(bmi, mu=22.5)
plot(height, weight)
hh  <- c(1.65, 1.70, 1.75, 1.80, 1.85, 1.90)
lines(hh, 22.5 * hh^2)
lines(hh, 22.5 * hh^2, col = "red")
x <- seq(-4, 4, 0.1)
plot(x, dnorm(x), type = 'l')
plot(x, dnorm(x))
plot(x, dnorm(x), type = 'l')
x <- 0:50
plot(x, dbinom(x, size=50, prob=.33), type = "h")
1 - pnorm(160, mean=132, sd=13)
pbinom(16, size = 20, prob = .5)
1 - pbinom(16, size = 20, prob = .5)
1 - pbinom(15, size = 20, prob = .5)
1 - pbinom(15,20,.5) + pbinom(4, 20, .5)
sem <- sigma / sqrt(n)
sem <- sigma / sqrt(n)
sem
xbar <- 83
sigma <- 12
n <- 5
sem <- sigma / sqrt(n)
sem
xbar + sem * qnorm(0.025)
xbar + sem * qnorm(0.975)
x <- rnorm(50)
mean(x)
sd(x)
var(x)
median(x)
rm(list = ls())
x <- rnorm(50)
mean(x)
sd(x)
var(x)
median(x)
quantile(x)
require(juul)
attach(juul)
require(datasets)
?datasets
library(lp = "datasets")
library(help = "datasets")
library(help = "datasets")
data("morley")
str(morley)
speed <- morley$Speed
mean(speed)
summary(morley)
hist(x)
mid.age <- c(2.5,7.5,13,16.5,17.5,19,22.5,44.5,70.5)
acc.count <- c(28,46,58,20,31,64,149,316,103)
age.acc <- rep(mid.age,acc.count)
?rep
brk <- c(0,5,10,16,17,18,20,25,60,80) # ??
hist(age.acc,breaks=brk)
n <- length(x)
ylim = c(0,1))
plot(sort(x),
(1:n)/n,
type = "s",
ylim = c(0,1))
qqnorm(x)
par(mfrow=c(1,2))
library(multcomp)
library(ggplot2)
ufo <- read.delim("data_science/machine_learning_for_hackers/ch01/ufo_awesome.tsv",
stringsAsFactors = FALSE,
header = FALSE,
na.strings = "")
rm(list = ls())
library(ggplot2)
ufo <- read.delim("data_science/machine_learning_for_hackers/ch01/ufo_awesome.tsv",
stringsAsFactors = FALSE,
header = FALSE,
na.strings = "")
head(ufo)
names(ufo) <- c("DateOccurred",
"DateReported",
"Location",
"ShortDescription",
"Duration",
"LongDescription")
head(ufo)
ufo$DateOccurred <- as.Date(ufo$DateOccurred,
format = "%Y%m%d")
head(ufo[which(nchar(ufo$DateOccurred)!=8 | nchar(ufo$DateReported)!=8), 1])
good.rows <- ifelse(nchar(ufo$DateOccurred)!= 8 | nchar(ufo$DateReported)!=8, FALSE, TRUE)
length(which(!good.rows))
ufo <- ufo[good.rows,]
ufo$DateOccurred <- as.Date(ufo$DateOccurred,
format = "%Y%m%d")
ufo$DateReported <- as.Date(ufo$DateReported,
format = "%Y%m%d")
city.state <- lapply(ufo$Location, get.location)
get.location <- function(l) {
split.location <- tryCatch(strsplit(1, ",")[[1]], error= function(e) return(c(NA, NA)))
clean.location <- gsub("^ ", "", split.location)
if (length(clean.location) > 2) {
return(c(NA,NA))
} else {
return(clean.location)
}
}
city.state <- lapply(ufo$Location, get.location)
head(city.state)
get.location <- function(l)
{
split.location <- tryCatch(strsplit(l, ",")[[1]],
error = function(e) return(c(NA, NA)))
clean.location <- gsub("^ ","",split.location)
if (length(clean.location) > 2)
{
return(c(NA,NA))
}
else
{
return(clean.location)
}
}
city.state <- lapply(ufo$Location, get.location)
head(city.state)
location.matrix <- do.call(rbind, city.state)
ufo <- transform(ufo,
USCity = location.matrix[,1],
USState = tolower(location.matrix[,2]),
stringsAsFactors = FALSE)
ufo$USState <- state.abb[match(ufo$USState, state.abb)]
us.states<-c("ak","al","ar","az","ca","co","ct","de","fl","ga","hi","ia","id","il",
"in","ks","ky","la","ma","md","me","mi","mn","mo","ms","mt","nc","nd","ne","nh",
"nj","nm","nv","ny","oh","ok","or","pa","ri","sc","sd","tn","tx","ut","va","vt",
"wa","wi","wv","wy")
us.states<-c("ak","al","ar","az","ca","co","ct","de","fl","ga","hi","ia","id","il",
"in","ks","ky","la","ma","md","me","mi","mn","mo","ms","mt","nc","nd","ne","nh",
"nj","nm","nv","ny","oh","ok","or","pa","ri","sc","sd","tn","tx","ut","va","vt",
"wa","wi","wv","wy")
ufo.us <- subset(ufo, !is.na(USState))
summary(ufo.us)
rm(list = ls())
library(ggplot2)
library(plyr)
library(scales)
ufo <- read.delim("data_science/machine_learning_for_hackers/ch01/ufo_awesome.tsv",
sep = "\t",
stringsAsFactors = FALSE,
header = FALSE,
na.strings = "")
summary(ufo)
head(ufo)
# set the column names
names(ufo) <- c("DateOccurred",
"DateReported",
"Location",
"ShortDescription",
"Duration",
"LongDescription")
good.rows <- ifelse(nchar(ufo$DateOccurred) != 8 |
nchar(ufo$DateReported) != 8,
FALSE,
TRUE)
length(which(!good.rows))
ufo$DateOccurred <- as.Date(ufo$DateOccurred,
format = "%Y%m%d")
ufo <- ufo[good.rows,] # only use good rows
ufo$DateOccurred <- as.Date(ufo$DateOccurred,
format = "%Y%m%d")
ufo$DateReported <- as.Date(ufo$DateReported,
format = "%Y%m%d")
get.location <- function(l)
{
split.location <- tryCatch(strsplit(l, ",")[[1]],
error = function(e) return(c(NA, NA)))
clean.location <- gsub("^ ","",split.location)
if (length(clean.location) > 2)
{
return(c(NA,NA))
}
else
{
return(clean.location)
}
}
city.state <- lapply(ufo$Location, get.location)
head(city.state)
location.matrix <- do.call(rbind, city.state)
ufo <- transform(ufo,
USCity = location.matrix[,1],
USState = tolower(location.matrix[,2]),
stringsAsFactors = FALSE)
ufo$USState <- state.abb[match(ufo$USState, state.abb)]
ufo.us <- subset(ufo, !is.na(USState))
summary(ufo.us)
head(ufo.us)
quick.hist <- ggplot(ufo.us, aes(x = DateOccurred)) +
geom_histogram() +
scale_x_date(breaks = "50 years")
ggsave(plot = quick.hist,
filename = "data_science/machine_learning_for_hackers/ch01/quick_hist.pdf",
height = 6,
width = 8)
ufo.us <- subset(ufo.us, DateOccurred >= as.Date("1990-01-01"))
new.hist <- ggplot(ufo.us, aes(x = DateOccurred)) +
geom_histogram(aes(fill='white', color='red')) +
scale_fill_manual(values=c('white'='white'), guide="none") +
scale_color_manual(values=c('red'='red'), guide="none") +
scale_x_date(breaks = "50 years")
ggsave(plot = new.hist,
filename = "data_science/machine_learning_for_hackers/ch01/quick_hist.pdf",
height = 6,
width = 8)
ggsave(plot = new.hist,
filename = "data_science/machine_learning_for_hackers/ch01/quick_hist.pdf",
height = 6,
width = 8)
ggsave(plot = new.hist,
filename = "data_science/machine_learning_for_hackers/ch01/new_hist.pdf",
height = 6,
width = 8)
ufo.us$YearMonth <- strftime(ufo.us$DateOccurred, format = "%Y-%m")
sightings.counts <- ddply(ufo.us, .(USState,YearMonth), nrow)
date.range <- seq.Date(from = as.Date(min(ufo.us$DateOccurred)),
to = as.Date(max(ufo.us$DateOccurred)),
by = "month")
install.packages("ISwR")
dataset = read.csv("../../datasets/Data_Preprocessing/Data.csv")
getwd()
setwd(".")
dataset = read.csv("../../datasets/Data_Preprocessing/Data.csv")
dataset = read.csv("datasets/Data_Preprocessing/Data.csv")
setwd("Github/machine-learning-a-z/")
dataset = read.csv("datasets/Data_Preprocessing/Data.csv")
View(location.matrix)
setwd("Github/machine-learning-a-z/")
dataset = read.csv("datasets/Data_Preprocessing/Data.csv")
View(dataset)
